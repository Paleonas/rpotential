#!/usr/bin/env python3
"""
Script pour g√©n√©rer des embeddings pour les documents de la base de donn√©es
Utilise OpenAI ada-002 pour g√©n√©rer des embeddings vectoriels
"""

import os
import sys
import psycopg2
from psycopg2.extras import execute_values
from openai import OpenAI
import time
from typing import List, Optional
from dotenv import load_dotenv

load_dotenv()

# Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://user:password@localhost:5432/legal_db")
EMBEDDING_MODEL = "text-embedding-ada-002"
BATCH_SIZE = 100  # Nombre de documents √† traiter par batch
MAX_RETRIES = 3

def get_db_connection():
    """√âtablit une connexion √† la base de donn√©es"""
    return psycopg2.connect(DATABASE_URL)

def get_documents_without_embeddings(limit: Optional[int] = None):
    """R√©cup√®re les documents qui n'ont pas encore d'embedding"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    query = """
        SELECT id, title, content, summary, document_type
        FROM legal_documents
        WHERE embedding IS NULL
        ORDER BY created_at ASC
    """
    
    if limit:
        query += f" LIMIT {limit}"
    
    cur.execute(query)
    documents = cur.fetchall()
    cur.close()
    conn.close()
    
    return documents

def generate_embedding(text: str, client: OpenAI) -> List[float]:
    """G√©n√®re un embedding pour un texte donn√©"""
    text = text.replace("\n", " ").strip()
    
    # Limiter la longueur du texte (max ~8000 tokens pour ada-002)
    if len(text) > 8000:
        text = text[:8000]
    
    try:
        response = client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"Erreur lors de la g√©n√©ration d'embedding: {e}")
        raise

def generate_embeddings_batch(texts: List[str], client: OpenAI) -> List[List[float]]:
    """G√©n√®re des embeddings pour un batch de textes"""
    embeddings = []
    for text in texts:
        try:
            embedding = generate_embedding(text, client)
            embeddings.append(embedding)
            time.sleep(0.1)  # Rate limiting
        except Exception as e:
            print(f"Erreur pour un document: {e}")
            embeddings.append(None)
    return embeddings

def prepare_text_for_embedding(title: str, content: str, summary: Optional[str] = None, doc_type: Optional[str] = None) -> str:
    """Pr√©pare le texte pour l'embedding en combinant title, summary et content"""
    parts = []
    
    if title:
        parts.append(f"Titre: {title}")
    
    if summary:
        parts.append(f"R√©sum√©: {summary}")
    
    if doc_type:
        parts.append(f"Type: {doc_type}")
    
    parts.append(f"Contenu: {content}")
    
    return "\n".join(parts)

def update_document_embeddings(document_ids: List[str], embeddings: List[List[float]]):
    """Met √† jour les embeddings dans la base de donn√©es"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    # Pr√©parer les donn√©es pour la mise √† jour
    data = [(embedding, doc_id) for embedding, doc_id in zip(embeddings, document_ids) if embedding is not None]
    
    if not data:
        print("Aucun embedding valide √† mettre √† jour")
        cur.close()
        conn.close()
        return
    
    query = """
        UPDATE legal_documents
        SET embedding = %s::vector
        WHERE id = %s
    """
    
    execute_values(cur, query, data, template=None, page_size=100)
    conn.commit()
    
    updated_count = cur.rowcount
    cur.close()
    conn.close()
    
    print(f"‚úì {updated_count} embeddings mis √† jour dans la base de donn√©es")

def process_all_documents():
    """Traite tous les documents sans embedding"""
    print("üöÄ D√©marrage de la g√©n√©ration d'embeddings...")
    
    if not OPENAI_API_KEY:
        print("‚ùå Erreur: OPENAI_API_KEY non d√©finie")
        sys.exit(1)
    
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    total_processed = 0
    total_errors = 0
    
    while True:
        # R√©cup√©rer un batch de documents
        documents = get_documents_without_embeddings(limit=BATCH_SIZE)
        
        if not documents:
            print(f"\n‚úÖ Traitement termin√©! {total_processed} documents trait√©s")
            break
        
        print(f"\nüìÑ Traitement de {len(documents)} documents...")
        
        document_ids = []
        texts = []
        
        for doc_id, title, content, summary, doc_type in documents:
            document_ids.append(str(doc_id))
            text = prepare_text_for_embedding(title, content, summary, doc_type)
            texts.append(text)
        
        # G√©n√©rer les embeddings
        try:
            embeddings = generate_embeddings_batch(texts, client)
            
            # Mettre √† jour la base de donn√©es
            update_document_embeddings(document_ids, embeddings)
            
            successful = sum(1 for e in embeddings if e is not None)
            total_processed += successful
            total_errors += len(embeddings) - successful
            
            print(f"‚úì Batch termin√©: {successful}/{len(documents)} r√©ussis")
            
        except Exception as e:
            print(f"‚ùå Erreur lors du traitement du batch: {e}")
            total_errors += len(documents)
        
        # Attendre un peu avant le prochain batch
        time.sleep(1)
    
    print(f"\nüìä R√©sum√© final:")
    print(f"   - Documents trait√©s: {total_processed}")
    print(f"   - Erreurs: {total_errors}")

def process_single_document(doc_id: str):
    """Traite un document sp√©cifique"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    cur.execute("""
        SELECT id, title, content, summary, document_type
        FROM legal_documents
        WHERE id = %s
    """, (doc_id,))
    
    doc = cur.fetchone()
    cur.close()
    conn.close()
    
    if not doc:
        print(f"‚ùå Document {doc_id} non trouv√©")
        return
    
    doc_id, title, content, summary, doc_type = doc
    
    client = OpenAI(api_key=OPENAI_API_KEY)
    text = prepare_text_for_embedding(title, content, summary, doc_type)
    
    print(f"üìÑ G√©n√©ration d'embedding pour: {title}")
    embedding = generate_embedding(text, client)
    update_document_embeddings([str(doc_id)], [embedding])
    print(f"‚úÖ Embedding g√©n√©r√© avec succ√®s")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        # Traiter un document sp√©cifique
        doc_id = sys.argv[1]
        process_single_document(doc_id)
    else:
        # Traiter tous les documents
        process_all_documents()
